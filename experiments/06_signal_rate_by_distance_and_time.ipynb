{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: gathering statistics about performance of detection algorithm (generating a \"detector spec\" for future system-level statistical simulations)\n",
    "\n",
    "### Note: much of the code built in this notebook has now been implemented in `ray_delay/ray_detector.py` for easier use in further experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scipy\n",
    "import mpmath\n",
    "import dill as pickle\n",
    "\n",
    "from ray_delay.noise_model_patch import NoiseModelPatch\n",
    "from ray_delay.ray_detector import RayDetectorSpec, RayModelType, RayDetector\n",
    "from stim_surface_code.memory import MemoryPatch\n",
    "from stim_surface_code.patch import Qubit, DataQubit, MeasureQubit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 13\n",
    "dz = 13\n",
    "dm = 7\n",
    "\n",
    "patch = NoiseModelPatch(MemoryPatch(dx, dz, dm))\n",
    "patch.noise_model.save_error_vals = True\n",
    "center_qubit = patch.patch.device[dx][dz].idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_radius = 6\n",
    "ray_qubit = center_qubit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndrome_qubits = patch.patch.get_syndrome_qubits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch.reset()\n",
    "baseline_fractions = np.mean(patch.patch.count_detection_events(1e6, return_full_data=True)[0], axis=0)\n",
    "\n",
    "ray_fractions = []\n",
    "times = np.linspace(0, 30e-3, 10)\n",
    "for time in times:\n",
    "    patch.reset()\n",
    "    patch.force_cosmic_ray(ray_qubit, ray_radius)\n",
    "    patch.step(time)\n",
    "    ray_fractions.append(np.mean(patch.patch.count_detection_events(1e6, return_full_data=True)[0], axis=0))\n",
    "\n",
    "baseline_fractions_labeled = {q.idx: baseline_fractions[i] for i,q in enumerate(syndrome_qubits)}\n",
    "ray_fractions_labeled = [{q.idx:r[i] for i,q in enumerate(syndrome_qubits)} for r in ray_fractions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _initialize_windows(\n",
    "        device: list[list[Qubit | None]],\n",
    "        spatial_window_size: int,\n",
    "        only_full_windows: bool = False,\n",
    "    ) -> list[list[int]]:\n",
    "    \"\"\"Initialize spatial windows that we will use to detect cosmic rays.\n",
    "    \n",
    "    Args:\n",
    "        device: The layout of the device, in the form of a 2D list of Qubit\n",
    "            objects.\n",
    "    \"\"\"\n",
    "    assert spatial_window_size < len(device) and spatial_window_size < len(device[0])\n",
    "    window_rows = (len(device) - spatial_window_size)//2 + 1\n",
    "    window_cols = (len(device[0]) - spatial_window_size)//2 + 1\n",
    "\n",
    "    min_qubit_count = spatial_window_size**2 if only_full_windows else 1\n",
    "\n",
    "    all_windows = []\n",
    "    for wr in range(window_rows):\n",
    "        for wc in range(window_cols):\n",
    "            window_qubits = []\n",
    "            for r in range(wr, wr + spatial_window_size):\n",
    "                for c in range(wc, wc + spatial_window_size):\n",
    "                    qb = device[2*r][2*c]\n",
    "                    if isinstance(qb, MeasureQubit):\n",
    "                        window_qubits.append(qb.idx)\n",
    "            if len(window_qubits) >= min_qubit_count:\n",
    "                all_windows.append(window_qubits)\n",
    "    return all_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpmath.mp.dps = 50\n",
    "\n",
    "cycles_per_distillation = 6*dm\n",
    "max_latency = cycles_per_distillation\n",
    "\n",
    "thresholds = [1-mpmath.mpf(1e-9), 1-mpmath.mpf(1e-10), 1-mpmath.mpf(1e-11), 1-mpmath.mpf(1e-13), 1-mpmath.mpf(1e-15)]\n",
    "temporal_window_size = max_latency\n",
    "spatial_size = 2\n",
    "\n",
    "detector_windows = _initialize_windows(patch.patch.device, spatial_size, only_full_windows=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.zeros(len(patch.patch.ancilla), dtype=float)\n",
    "center_coords = patch.patch.qubit_name_dict[center_qubit].coords\n",
    "\n",
    "for i,qubit in enumerate(patch.patch.ancilla):\n",
    "    coords = qubit.coords\n",
    "    distances[i] = np.sqrt((coords[0]-center_coords[0])**2 + (coords[1]-center_coords[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_distances = []\n",
    "qubits_per_distance = []\n",
    "for i,dst in enumerate(distances):\n",
    "    qubit = patch.patch.ancilla[i].idx\n",
    "    dst_rounded = np.round(dst, 2)\n",
    "    if dst_rounded not in unique_distances:\n",
    "        unique_distances.append(dst_rounded)\n",
    "        qubits_per_distance.append([qubit])\n",
    "    else:\n",
    "        qubits_per_distance[unique_distances.index(dst_rounded)].append(qubit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubits_per_distance = np.array(qubits_per_distance, dtype=object)[np.argsort(unique_distances)]\n",
    "unique_distances = np.sort(unique_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_distillation_signal_rate_by_distance = np.zeros((len(thresholds), max_latency, len(unique_distances)), dtype=mpmath.mpf)\n",
    "signal_rates = np.zeros((len(thresholds), max_latency, len(detector_windows)), dtype=mpmath.mpf)\n",
    "for i,threshold in enumerate(thresholds):\n",
    "    for latency in range(max_latency):\n",
    "        for k,window in enumerate(detector_windows):\n",
    "            baseline_mean = np.mean([baseline_fractions_labeled[q] for q in window]) # mean per qubit per round\n",
    "            ray_mean = np.mean([ray_fractions_labeled[0][q] for q in window])\n",
    "\n",
    "            # threshold of detections where we say it is outside of the baseline regime\n",
    "            detection_threshold = scipy.stats.binom.ppf(float(threshold), len(window)*temporal_window_size, baseline_mean)\n",
    "        \n",
    "            if latency <= temporal_window_size:\n",
    "                # some part of window is at baseline rate (before ray has hit)\n",
    "                windowed_syndrome_rate = baseline_mean*(1-latency/temporal_window_size) + ray_mean*(latency/temporal_window_size)\n",
    "            else:\n",
    "                windowed_syndrome_rate = ray_mean\n",
    "            detection_prob = 1-scipy.stats.binom.cdf(detection_threshold, len(window)*temporal_window_size, windowed_syndrome_rate)\n",
    "            signal_rates[i,latency,k] = mpmath.mpf(detection_prob)\n",
    "\n",
    "qubit_no_signal_rates = np.ones((len(thresholds), max_latency, len(patch.patch.all_qubits)), dtype=mpmath.mpf)\n",
    "for i,threshold in enumerate(thresholds):\n",
    "    for latency in range(max_latency):\n",
    "        for k,window in enumerate(detector_windows):\n",
    "            signal_rate = signal_rates[i,latency,k]\n",
    "            for q in window:\n",
    "                qubit_no_signal_rates[i,latency,q] *= (1-signal_rate)\n",
    "\n",
    "no_ray_signal_rates = 1-qubit_no_signal_rates[:,0]\n",
    "false_positive_rate = np.mean(no_ray_signal_rates, axis=1)\n",
    "\n",
    "for k,dst in enumerate(unique_distances):\n",
    "    for q in qubits_per_distance[k]:\n",
    "        first_distillation_signal_rate_by_distance[:,:,k] += (1-qubit_no_signal_rates[:,:,q])\n",
    "    first_distillation_signal_rate_by_distance[:,:,k] /= len(qubits_per_distance[k])\n",
    "\n",
    "    # lower bound by average false positive rate\n",
    "    for latency in range(max_latency):\n",
    "        first_distillation_signal_rate_by_distance[:,latency,k] = np.maximum(first_distillation_signal_rate_by_distance[:,latency,k], false_positive_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([mpf('0.00000000082071655441326366127512546054126606408554663299160744'),\n",
       "       mpf('0.000000000058020948412073934442477973231466319772838398151104739'),\n",
       "       mpf('0.0000000000049633518528024050016748584634892980292378500010742501'),\n",
       "       mpf('0.000000000000048491379062498071105678889776603876379698722435370873'),\n",
       "       mpf('0.00000000000000054160434791802860194867415294295673484029508003614488')],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decaying_signal_rate_by_distance = np.zeros((len(thresholds), len(times), len(unique_distances)), dtype=mpmath.mpf)\n",
    "signal_rates = np.zeros((len(thresholds), len(times), len(detector_windows)), dtype=mpmath.mpf)\n",
    "for i,threshold in enumerate(thresholds):\n",
    "    for j,time in enumerate(times):\n",
    "        for k,window in enumerate(detector_windows):\n",
    "            windowed_syndrome_rate = np.mean([ray_fractions_labeled[j][q] for q in window])\n",
    "\n",
    "            # threshold of detections where we say it is outside of the baseline regime\n",
    "            detection_threshold = scipy.stats.binom.ppf(float(threshold), len(window)*temporal_window_size, baseline_mean)\n",
    "\n",
    "            detection_prob = 1-scipy.stats.binom.cdf(detection_threshold, len(window)*temporal_window_size, windowed_syndrome_rate)\n",
    "            signal_rates[i,j,k] = mpmath.mpf(detection_prob)\n",
    "\n",
    "qubit_no_signal_rates = np.ones((len(thresholds), len(times), len(patch.patch.all_qubits)), dtype=mpmath.mpf)\n",
    "for i,threshold in enumerate(thresholds):\n",
    "    for j,time in enumerate(times):\n",
    "        for k,window in enumerate(detector_windows):\n",
    "            signal_rate = signal_rates[i,j,k]\n",
    "            for q in window:\n",
    "                qubit_no_signal_rates[i,j,q] *= (1-signal_rate)\n",
    "\n",
    "for k,dst in enumerate(unique_distances):\n",
    "    for q in qubits_per_distance[k]:\n",
    "        decaying_signal_rate_by_distance[:,:,k] += (1-qubit_no_signal_rates[:,:,q])\n",
    "    decaying_signal_rate_by_distance[:,:,k] /= len(qubits_per_distance[k])\n",
    "\n",
    "    # lower bound by average false positive rate\n",
    "    for j,time in enumerate(times):\n",
    "        decaying_signal_rate_by_distance[:,j,k] = np.maximum(decaying_signal_rate_by_distance[:,j,k], false_positive_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray_delay.ray_detector import RayDetectorSpec, RayModelType, RayDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,threshold in enumerate(thresholds):\n",
    "    ray_detector_spec = RayDetectorSpec(\n",
    "        detector_spatial_window_size = spatial_size,\n",
    "        detector_temporal_window_size = temporal_window_size,\n",
    "        ray_model_type = RayModelType.LINEAR_ERR,\n",
    "        ray_radius = ray_radius,\n",
    "        ray_max_strength = 0.99,\n",
    "        detection_distances = unique_distances,\n",
    "        times_after_ray_impact = times,\n",
    "        first_distillation_signal_rates = first_distillation_signal_rate_by_distance[i],\n",
    "        decaying_signal_rates = decaying_signal_rate_by_distance[i],\n",
    "        baseline_signal_rate = false_positive_rate.astype(float)[i]\n",
    "    )\n",
    "    pickle.dump(ray_detector_spec, open(f'detection_chance_functions/linear_err_thresh=1e{int(np.round(np.log10(float(1-threshold))))}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40533066666666673,\n",
       " 0.1158465,\n",
       " 0.07330733333333334,\n",
       " 0.056634833333333336,\n",
       " 0.047675,\n",
       " 0.04226133333333334,\n",
       " 0.03850766666666667,\n",
       " 0.0360005,\n",
       " 0.03376216666666667,\n",
       " 0.03218466666666667]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.max(np.array(list(ray_fractions_labeled[i].values()))) for i in range(len(ray_fractions_labeled))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'signal_rate_by_distance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(times, \u001b[43msignal_rate_by_distance\u001b[49m[\u001b[38;5;241m0\u001b[39m,:,:,\u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'signal_rate_by_distance' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(times, signal_rate_by_distance[0,:,:,10].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray-delay-mG6OZh6y-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
